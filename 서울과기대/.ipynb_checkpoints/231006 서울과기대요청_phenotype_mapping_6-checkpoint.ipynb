{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284796/4165121815.py:234: DtypeWarning: Columns (1,2,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  network_data = pd.read_csv(\"/data/home/sss2061/식약처/Data/BIOGRID-ORGANISM-Homo_sapiens.tab3.txt\", sep=\"\\t\", encoding=\"cp949\")\n"
     ]
    }
   ],
   "source": [
    "# rwr 조화평균 완료\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "import os\n",
    "import ast\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import csv\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "from statistics import harmonic_mean\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def calculate_mean(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "def calculate_standard_deviation(numbers):\n",
    "    return statistics.stdev(numbers)\n",
    "\n",
    "def combine_lists(full_list):\n",
    "    combined = defaultdict(list)\n",
    "    \n",
    "    # 모든 리스트에 대한 처리\n",
    "    for sublist in full_list:\n",
    "        for item in sublist:\n",
    "            entrez_id, rwr_score = item\n",
    "            combined[entrez_id].append(rwr_score)\n",
    "    \n",
    "    # 조화평균 및 결과 리스트 만들기\n",
    "    result = []\n",
    "    for entrez_id, scores in combined.items():\n",
    "        if len(scores) == 1:\n",
    "            result.append([entrez_id, scores[0]])  # 값이 하나면 그대로 추가\n",
    "        else:\n",
    "            # 조화평균 계산\n",
    "            harmonic_mean_score = harmonic_mean(scores)\n",
    "            result.append([entrez_id, harmonic_mean_score])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compound_target(compoundid):\n",
    "\n",
    "    conn_cur.execute(f\"with tmp1 as (select cg.geneid from compound_gene cg where (cg.compid = '{compoundid}' and cg.relationsign in ('activate','inhibit')))\" \n",
    "                    f\"select g.entrezid from gene g,tmp1 where g.geneid=tmp1.geneid;\")\n",
    "    compound_gene1=conn_cur.fetchall()\n",
    "\n",
    "    compound_gene=set(compound_gene1)\n",
    "    compound_gene=list(compound_gene)\n",
    "    \n",
    "    # Compound-target gene List 생성\n",
    "    target_gene_list = [] \n",
    "    for i in range(len(compound_gene)):\n",
    "        interaction_gene = compound_gene[i][0]\n",
    "        if interaction_gene in entrez_list:\n",
    "            target_gene_list.append(interaction_gene)        \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # restart node에 적용할 target gene List 생성\n",
    "    target_node = [] \n",
    "    for entrez in target_gene_list:\n",
    "        node_ = node_index.get(entrez) \n",
    "        target_node.append(node_)\n",
    "\n",
    "    conn_cur.execute(f\"with tmp2 as (select cg.geneid from compound_gene cg where cg.compid = '{compoundid}' and relationsign='associate')\" \n",
    "                    f\"select g.entrezid from gene g,tmp2 where g.geneid=tmp2.geneid;\")\n",
    "\n",
    "    compound_gene2=conn_cur.fetchall()\n",
    "\n",
    "    compound_gene=set(compound_gene2)\n",
    "    compound_gene=list(compound_gene)\n",
    "\n",
    "    indirected_target_gene_list = [] \n",
    "    for i in range(len(compound_gene)):\n",
    "        interaction_gene = compound_gene[i][0]\n",
    "        if interaction_gene in entrez_list:\n",
    "            indirected_target_gene_list.append(interaction_gene)        \n",
    "        else:\n",
    "            continue      \n",
    "\n",
    "    num1=len(target_gene_list) #target gene list 갯수\n",
    "    directed_target_gene_list.append(num1)\n",
    "    num2=len(indirected_target_gene_list) #indirected target gene list 갯수 \n",
    "    indirected_target_gene_list_count.append(num2)\n",
    "    \n",
    "    print(\"Compound\",compoundid,\"Target gene 개수\",num1)\n",
    "    print(\"Compound\",compoundid,\"indirected_Target gene 개수\",num2)\n",
    "    \n",
    "    #indirect nodes 정의\n",
    "    indirect_nodes= []\n",
    "    for entrez in indirected_target_gene_list:\n",
    "        node_ = node_index.get(entrez) \n",
    "        indirect_nodes.append(node_)\n",
    "\n",
    "    # PPI network RWR을 위한 initialize\n",
    "    initialized = RWR_initializing(G, seed_nodes=target_node,indirect_target_nodes=indirect_nodes, is_weighted=False) \n",
    "\n",
    "    # RWR 실행\n",
    "    rwr = RWR(initialized=initialized, prob=0.2, max_iter=100, tol=1.0e-6)\n",
    "    rwr_mapping_entrez = [[entrez_list[i], rwr[node_index.get(entrez_list[i])]] for i in range(len(entrez_list))]\n",
    "    \n",
    "    var_name1 = f'{compoundid}_num1'\n",
    "    var_name2 = f'{compoundid}_num2'\n",
    "\n",
    "    # 전역 변수 설정\n",
    "    globals()[var_name1] = num1\n",
    "    globals()[var_name2] = num2\n",
    "    \n",
    "    return rwr_mapping_entrez\n",
    "\n",
    "def rwr_compound_target(count,entrez_list):\n",
    "    \n",
    "    num1=directed_target_gene_list[count]\n",
    "    num2=indirected_target_gene_list_count[count]\n",
    "    \n",
    "    random_interaction_gene1 = random.sample(entrez_list, num1)\n",
    "    remaining_entrez_list = [gene for gene in entrez_list if gene not in random_interaction_gene1]\n",
    "    random_interaction_gene2 = random.sample(remaining_entrez_list, num2)\n",
    "# restart node에 적용할 target gene List 생성\n",
    "    target_node = [] \n",
    "    for entrez in random_interaction_gene1:\n",
    "        node_ = node_index.get(entrez)\n",
    "        target_node.append(node_)\n",
    "\n",
    "    #indirect nodes 정의\n",
    "    indirect_nodes= []\n",
    "    for entrez in random_interaction_gene2:\n",
    "        node_ = node_index.get(entrez)\n",
    "        indirect_nodes.append(node_)\n",
    "\n",
    "    # PPI network RWR을 위한 initialize\n",
    "    initialized = RWR_initializing(G, seed_nodes=target_node,indirect_target_nodes=indirect_nodes, is_weighted=False) \n",
    "    \n",
    "# RWR 실행\n",
    "    rwr=RWR(initialized=initialized, prob=0.2, max_iter=100, tol=1.0e-6)\n",
    "    rwr_mapping_entrez = [[entrez_list[i], rwr[node_index.get(entrez_list[i])]] for i in range(len(entrez_list))]\n",
    "    return rwr_mapping_entrez\n",
    "\n",
    "def create_ppi_network(network_data):\n",
    "    network_data = network_data.astype({'Entrez Gene Interactor A': str,\n",
    "                                        'Entrez Gene Interactor B': str})\n",
    "\n",
    "    # symbol list를 생성하고 unique 값만 가지도록 생성\n",
    "    symbolA = network_data.loc[:, 'Entrez Gene Interactor A'].to_list()\n",
    "    symbolB = network_data.loc[:, 'Entrez Gene Interactor B'].to_list()\n",
    "\n",
    "    symbol_list = symbolA + symbolB \n",
    "    symbol_list = set(symbol_list) \n",
    "    symbol_list = list(symbol_list)\n",
    "\n",
    "    # 모든 symbol에 index를 딕셔너리에서 부여\n",
    "    node_index = {}\n",
    "    for i in range(len(symbol_list)):\n",
    "        node_index[symbol_list[i]] = i\n",
    "\n",
    "    # index로 node_list 생성\n",
    "    node_list = node_index.values()\n",
    "\n",
    "    # index로 edge_list 생성\n",
    "    edge_list = network_data[['Entrez Gene Interactor A', 'Entrez Gene Interactor B']].values.tolist()  #\n",
    "    for i in range(len(edge_list)):\n",
    "        edge_list[i][0] = node_index.get(edge_list[i][0])\n",
    "        edge_list[i][1] = node_index.get(edge_list[i][1])\n",
    "    \n",
    "    # 무방향 그래프 오브젝트 생성\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # 그래프에 노드 추가\n",
    "    G.add_nodes_from(node_list)\n",
    "\n",
    "    # 그래프에 엣지 추가\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    print(f'Number of created nodes: {G.number_of_nodes()}')\n",
    "    print(f'Number of created edges: {G.number_of_edges()}')\n",
    "\n",
    "    return G, node_index\n",
    "\n",
    "def RWR_initializing(G, seed_nodes, indirect_target_nodes, is_weighted=False):\n",
    "    norm_A = np.zeros(shape=(len(G), len(G)))\n",
    "    if is_weighted:  \n",
    "        for i, neighbor_dict in G.adjacency():\n",
    "            for j, v in neighbor_dict.items():\n",
    "                norm_A[i][j] = v.get(\"weight\", 1 / len(neighbor_dict))\n",
    "    else:  \n",
    "        for i, neighbor_dict in G.adjacency():  \n",
    "            for j, v in neighbor_dict.items():  \n",
    "                norm_A[i][j] = 1 / len(neighbor_dict)\n",
    "    \n",
    "    # seed nodes와 indirect target nodes를 모두 포함한 딕셔너리 생성\n",
    "    personalization = {node: 1 for node in seed_nodes}\n",
    "    for node in indirect_target_nodes:\n",
    "        personalization[node] = 0.3  \n",
    "        \n",
    "    r_0 = np.array([personalization.get(n, 0) for n in range(len(G))]) \n",
    "    r_c = np.repeat(1 / len(G), len(G)) \n",
    "    return {\"norm_A\": norm_A, \"r_0\": r_0, \"r_c\": r_c, \"N\": len(G)}\n",
    "\n",
    "def RWR(initialized, prob=0.85, max_iter=100, tol=1.0e-6):\n",
    "    if initialized is None:\n",
    "        raise ValueError('initialized information must be required')\n",
    "\n",
    "    norm_A = initialized['norm_A']  # 인접행렬 A (정규화된)\n",
    "    r_0 = initialized['r_0']        # 시작 노드\n",
    "    r_c = initialized['r_c']        # 가중치 행렬\n",
    "    N = initialized['N']            # 노드의 개수\n",
    "    for iteration in range(max_iter):\n",
    "        r_prev = r_c\n",
    "        r_c = prob * r_c @ norm_A + (1 - prob) * r_0  # RWR algorithm\n",
    "        err = np.absolute(r_c - r_prev).sum()\n",
    "        if err < N * tol:\n",
    "            print(f'RWR iteration = {iteration + 1}')\n",
    "            print('Converged')\n",
    "            return r_c\n",
    "        else:\n",
    "            print(f'RWR iteration = {iteration + 1}, Iteration until convergence ...')\n",
    "            print(f'{err} -> {N * tol}')\n",
    "    return \"NotConverged\"\n",
    "\n",
    "# postgresql DB 연동\n",
    "config = configparser.ConfigParser()\n",
    "config.read('db_config.ini')\n",
    "conn=psycopg2.connect(host=\"168.131.30.66\", dbname=\"coconut\",user=\"dbuser\",password=\"jnudl1\") #데이터이름변경\n",
    "conn_cur = conn.cursor()\n",
    "\n",
    "# BIOGRID-Homo_sapiens Data 기반 PPI Network 구축\n",
    "network_data = pd.read_csv(\"/data/home/sss2061/식약처/Data/BIOGRID-ORGANISM-Homo_sapiens.tab3.txt\", sep=\"\\t\", encoding=\"cp949\")  \n",
    "G, node_index = create_ppi_network(network_data=network_data)  \n",
    "entrez_list = list(node_index.keys())  \n",
    "\n",
    "# 네트워크 활용 gene_phenotype 정보 생성\n",
    "gene_phenotype_file = '/data/home/sss2061/식약처/gene_2023_phenotype_info.csv'\n",
    "if os.path.isfile(gene_phenotype_file): \n",
    "    gene_phenotype_df = pd.read_csv(gene_phenotype_file, encoding='UTF-8', converters={'Phenotype': ast.literal_eval}) \n",
    "else: \n",
    "    gene_phenotype_info = {}\n",
    "    for g in range(len(entrez_list)):\n",
    "        conn_cur.execute(f\"with tmp1 as (select g.geneid from gene g where g.entrezid = '{entrez_list[g]}'),\"\n",
    "                         f\"tmp2 as (select gp.phenid from gene_phenotype gp, tmp1 where gp.geneid = tmp1.geneid)\"\n",
    "                         f\"select distinct p.name from phenotype p, tmp2 where p.phenid = tmp2.phenid;\")\n",
    "        # TASS DB 기반 gene-phenotype 정보 추출\n",
    "        selected_phenotype = conn_cur.fetchall()\n",
    "        phenotypes = []\n",
    "        for i in range(len(selected_phenotype)):\n",
    "             phenotypes.append(selected_phenotype[i][0]) \n",
    "        gene_phenotype_info[entrez_list[g]] = phenotypes\n",
    "        print(f'{g + 1}/{len(entrez_list)}')\n",
    "    gene_phenotype_mapping = [[entrez_list[i], gene_phenotype_info.get(entrez_list[i])] for i in range(len(entrez_list))]\n",
    "    gene_phenotype_df = pd.DataFrame(data=gene_phenotype_mapping, columns=['Entrez ID', 'Phenotype'])\n",
    "    gene_phenotype_df.to_csv(gene_phenotype_file, index=False, encoding='UTF-8')\n",
    "\n",
    "phenotype_list = []\n",
    "for phen_list in gene_phenotype_df['Phenotype']:\n",
    "    for phen in phen_list:\n",
    "        if phen not in phenotype_list:\n",
    "            phenotype_list.append(phen)\n",
    "\n",
    "Compound_list=['CP00542400','CP04483923','CP04483926'] #사용자가 입력하는 compound list\n",
    "\n",
    "global directed_target_gene_list\n",
    "directed_target_gene_list=[]  #사용자가 입력한 compound의 direct target gene 개수가 들어있는 list\n",
    "\n",
    "global indirected_target_gene_list_count\n",
    "indirected_target_gene_list_count=[] #사용자가 입력한 compound의 indirect target gene 개수가 들어있는 list\n",
    "\n",
    "rwr_mapping_entrez_list=[] #사용자가 입력한 compound 별 rwr mapping entrez가 들어있는 list\n",
    "\n",
    "for c in range(len(Compound_list)):\n",
    "    \n",
    "    compoundid1=Compound_list[c]\n",
    "    \n",
    "    rwr_mapping_entrez=compound_target(compoundid1)\n",
    "    rwr_mapping_entrez_list.append(rwr_mapping_entrez)\n",
    "\n",
    "rwr_mapping_entrez2 = combine_lists(rwr_mapping_entrez_list) #rwr mapping 조화평균 추출\n",
    "\n",
    "rwr_result = pd.DataFrame(data=rwr_mapping_entrez2, columns=['Entrez ID', 'RWR_score'])\n",
    "rwr_result = pd.merge(rwr_result, gene_phenotype_df, how='outer')\n",
    "rwr_result['Phenotype'].loc[rwr_result['Phenotype'].isnull()] = rwr_result['Phenotype'].loc[\n",
    "    rwr_result['Phenotype'].isnull()].apply(lambda x: [])\n",
    "rwr_result = rwr_result.sort_values(by='RWR_score', ascending=False)\n",
    "\n",
    "# phenotype 별 RWR score를 계산하기 위한 딕셔너리 생성\n",
    "phenotype_rwr_score_dict = {}\n",
    "for phen in phenotype_list:\n",
    "    phenotype_rwr_score_dict[phen] = 0    \n",
    "    \n",
    "# 각 phenotype 별 RWR score 확인\n",
    "for i in range(len(rwr_result)):\n",
    "    rwr_score = rwr_result['RWR_score'].iloc[i]\n",
    "    if rwr_result['Phenotype'].iloc[i]:\n",
    "        for phen in rwr_result['Phenotype'].iloc[i]:\n",
    "            phenotype_rwr_score_dict[phen] += rwr_score\n",
    "\n",
    "Phenotype_score_Phenotype=list(phenotype_rwr_score_dict.keys())\n",
    "Phenotype_score_Score=list(phenotype_rwr_score_dict.values())\n",
    "\n",
    "#network score. csv 파일로 저장\n",
    "inferred_phenotype2 = pd.DataFrame(data=[pair for pair in zip(list(phenotype_rwr_score_dict.keys()),\n",
    "                                                             list(phenotype_rwr_score_dict.values()))],\n",
    "                                  columns=['Phenotype', 'Network_score'])\n",
    "inferred_phenotype2 = inferred_phenotype2.sort_values(by='Network_score', ascending=False)\n",
    "\n",
    "# if not os.path.exists('compound 결과'):\n",
    "#     os.makedirs('compound 결과')\n",
    "inferred_phenotype2.to_csv('6_network_score.csv',index=False, encoding='UTF-8')\n",
    "\n",
    "#----------------------------------------------------------------1,000\n",
    "output_dict={}\n",
    "print(\"확인용 바깥\",indirected_target_gene_list_count) #확인용\n",
    "for h in range(1000):\n",
    "    p_rwr_mapping_entrez_list=[] #1번당 compound별 random target gene rwr mapping list\n",
    "    \n",
    "    print(h,\"번째 상황\") # 제거\n",
    "    for k in range(len(Compound_list)):\n",
    "        rwr_mapping_entrez=rwr_compound_target(k,entrez_list)\n",
    "        p_rwr_mapping_entrez_list.append(rwr_mapping_entrez)\n",
    "    \n",
    "    rwr_mapping_entrez3 = combine_lists(p_rwr_mapping_entrez_list) #rwr mapping 조화평균 추출\n",
    "    \n",
    "    rwr_result = pd.DataFrame(data=rwr_mapping_entrez3, columns=['Entrez ID', 'RWR_score'])\n",
    "    rwr_result = pd.merge(rwr_result, gene_phenotype_df, how='outer')\n",
    "    rwr_result['Phenotype'].loc[rwr_result['Phenotype'].isnull()] = rwr_result['Phenotype'].loc[rwr_result['Phenotype'].isnull()].apply(lambda x: [])\n",
    "    rwr_result = rwr_result.sort_values(by='RWR_score', ascending=False)\n",
    "    \n",
    "# phenotype 별 RWR score를 계산하기 위한 딕셔너리 생성\n",
    "    phenotype_rwr_score_dict = {}\n",
    "    for phen in phenotype_list:\n",
    "        phenotype_rwr_score_dict[phen] = 0\n",
    "\n",
    "# 각 phenotype 별 RWR score 확인\n",
    "    for i in range(len(rwr_result)):\n",
    "        rwr_score = rwr_result['RWR_score'].iloc[i]\n",
    "        if rwr_result['Phenotype'].iloc[i]:\n",
    "            for phen in rwr_result['Phenotype'].iloc[i]:\n",
    "                phenotype_rwr_score_dict[phen] += rwr_score\n",
    "\n",
    "    key_list=list(phenotype_rwr_score_dict.keys())\n",
    "    for i in key_list:\n",
    "        if i not in output_dict:\n",
    "            output_dict[i]=list([phenotype_rwr_score_dict[i]])\n",
    "        else:\n",
    "            output_dict[i].append(phenotype_rwr_score_dict[i])\n",
    "print(\"rwr 종료\")\n",
    "\n",
    "#rwr. score csv 파일로 저장\n",
    "inferred_phenotype3 = pd.DataFrame(data=[pair for pair in zip(list(output_dict.keys()),\n",
    "                                                             list(output_dict.values()))],\n",
    "                                  columns=['Phenotype', 'Network_score'])\n",
    "inferred_phenotype3 = inferred_phenotype3.sort_values(by='Network_score', ascending=False)\n",
    "\n",
    "inferred_phenotype3.to_csv('6_P_value.csv',index=False, encoding='UTF-8')\n",
    "\n",
    "P_value_Phenotype=list(output_dict.keys())\n",
    "P_value_Score=list(output_dict.values())\n",
    "\n",
    "#----------------------------------------------------------------z-score  \n",
    "count=0\n",
    "z_score_list=[]\n",
    "outlier_list=[] #제거가능\n",
    "P_value_list=[]\n",
    "rank_number=0\n",
    "\n",
    "for i in range(len(P_value_Score)):\n",
    "    Numberlist=P_value_Score[i].copy()\n",
    "    Numberlist.append(Phenotype_score_Score[i])\n",
    "\n",
    "    # 평균 계산\n",
    "    mean = calculate_mean(Numberlist)\n",
    "\n",
    "    # 표준편차 계산\n",
    "    std_deviation = calculate_standard_deviation(Numberlist)\n",
    "\n",
    "    z_score=(Phenotype_score_Score[i]-mean)/std_deviation\n",
    "    z_score_list.append(z_score)\n",
    "    if z_score >=-2.58 and z_score<=2.58: #제거가능\n",
    "        outlier=1\n",
    "        count=count+1\n",
    "    else:\n",
    "        outlier=0 \n",
    "    outlier_list.append(outlier) #제거가능\n",
    "\n",
    "    Numberlist.sort(reverse=True)\n",
    "\n",
    "    rank=Numberlist.index(Phenotype_score_Score[i]) #순위찾기\n",
    "    if rank<5:\n",
    "        rank_number=rank_number+1\n",
    "    P_value_list.append(rank)\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "phenotype_umlsid = []\n",
    "# phenotype_list를 순회하면서 각 이름에 대한 UMLS ID를 가져옴\n",
    "for phen_name in Phenotype_score_Phenotype:\n",
    "    # 이름에 단일 따옴표가 포함된 경우 이스케이프\n",
    "    escaped_name = phen_name.replace(\"'\", \"''\")\n",
    "    \n",
    "    conn_cur.execute(f\"SELECT umlsid FROM phenotype WHERE name = '{escaped_name}'\")\n",
    "    umlsid_result = conn_cur.fetchone()\n",
    "    \n",
    "    # UMLS ID가 존재하면 리스트에 추가\n",
    "    if umlsid_result:\n",
    "        phenotype_umlsid.append(umlsid_result[0])\n",
    "    else:\n",
    "        # UMLS ID가 없는 경우에 대한 처리 (예: None 또는 다른 기본값)\n",
    "        phenotype_umlsid.append(None)\n",
    "\n",
    "# 결과를 DataFrame으로 만들어 저장\n",
    "phenotype_umlsid_df = pd.DataFrame({'Name': Phenotype_score_Phenotype, 'UMLSID': phenotype_umlsid})\n",
    "print(phenotype_umlsid_df)\n",
    "\n",
    "#------------------------\n",
    "\n",
    "#     Phenotype_score['Phenotype']=Phenotype_score_Phenotype\n",
    "#     Phenotype_score['Network_score']=Phenotype_score_Score\n",
    "#     Phenotype_score['z-score']=z_score_list\n",
    "#     Phenotype_score['outlier']=outlier_list\n",
    "\n",
    "#     # Compound ID에 해당하는 inferred phenotype.csv 생성\n",
    "Phenotype_score = pd.DataFrame({\n",
    "    'Phenotype': Phenotype_score_Phenotype,\n",
    "    'Network_score': Phenotype_score_Score,\n",
    "    'z-score': z_score_list,\n",
    "    'P-value': P_value_list,\n",
    "    'UMLSID': phenotype_umlsid\n",
    "})\n",
    "\n",
    "Phenotype_score=Phenotype_score.sort_values(by='P-value',ascending=True)\n",
    "\n",
    "#     # Compound ID에 해당하는 inferred phenotype.csv 생성\n",
    "# if not os.path.exists('compound 결과'):\n",
    "#     os.makedirs('compound 결과')\n",
    "Phenotype_score.to_csv('6_검증.csv',index=False, encoding='UTF-8')\n",
    "    \n",
    "end = time.time()\n",
    "sec = (end - start)\n",
    "result = datetime.timedelta(seconds=sec)\n",
    "print(\"걸린 시간 : \",result)\n",
    "print(f\"걸린 시간 : {end - start:.5f} sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jy1",
   "language": "python",
   "name": "jy1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
